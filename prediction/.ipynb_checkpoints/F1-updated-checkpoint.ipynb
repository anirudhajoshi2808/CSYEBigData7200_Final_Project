{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3b298b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://10.110.168.85:4040\n",
       "SparkContext available as 'sc' (version = 3.3.2, master = local[*], app id = local-1681860604862)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/18 19:30:08 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@34d7cce2\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession\n",
    "  .builder()\n",
    "  .appName(\"F1 Updated\")\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed297a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sc: org.apache.spark.SparkContext = org.apache.spark.SparkContext@4b22d33b\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81801c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drivers: org.apache.spark.sql.DataFrame = [driverId: string, driverRef: string ... 7 more fields]\n",
       "races: org.apache.spark.sql.DataFrame = [raceId: string, year: string ... 16 more fields]\n",
       "quali: org.apache.spark.sql.DataFrame = [qualifyId: string, raceId: string ... 7 more fields]\n",
       "results: org.apache.spark.sql.DataFrame = [resultId: string, raceId: string ... 16 more fields]\n",
       "constructors: org.apache.spark.sql.DataFrame = [constructorId: string, constructorRef: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val drivers = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .load(\"../data/drivers.csv\")\n",
    "\n",
    "val races = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .load(\"../data/races.csv\")\n",
    "\n",
    "val quali = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .load(\"../data/qualifying.csv\")\n",
    "\n",
    "val results = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .load(\"../data/results.csv\")\n",
    "\n",
    "val constructors = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .load(\"../data/constructors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "228662ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hungarianResults: org.apache.spark.sql.DataFrame = [driverId: string, resultId: string ... 17 more fields]\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/// Hungary Grand Prix for 2020\n",
    "val hungarianResults = results\n",
    "  .filter($\"raceId\" === 1034 && $\"position\" =!= \"\\\\N\")\n",
    "  .join(drivers.select($\"driverId\", $\"surname\"), Seq(\"driverId\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2244fada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- resultId: string (nullable = true)\n",
      " |-- raceId: string (nullable = true)\n",
      " |-- driverId: string (nullable = true)\n",
      " |-- constructorId: string (nullable = true)\n",
      " |-- number: string (nullable = true)\n",
      " |-- grid: string (nullable = true)\n",
      " |-- position: string (nullable = true)\n",
      " |-- positionText: string (nullable = true)\n",
      " |-- positionOrder: string (nullable = true)\n",
      " |-- points: string (nullable = true)\n",
      " |-- laps: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- milliseconds: string (nullable = true)\n",
      " |-- fastestLap: string (nullable = true)\n",
      " |-- rank: string (nullable = true)\n",
      " |-- fastestLapTime: string (nullable = true)\n",
      " |-- fastestLapSpeed: string (nullable = true)\n",
      " |-- statusId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hungarianResults.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a414dfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+------+-------------+------+----+--------+------------+-------------+------+----+-----------+------------+----------+----+--------------+---------------+--------+----------+\n",
      "|driverId|resultId|raceId|constructorId|number|grid|position|positionText|positionOrder|points|laps|       time|milliseconds|fastestLap|rank|fastestLapTime|fastestLapSpeed|statusId|   surname|\n",
      "+--------+--------+------+-------------+------+----+--------+------------+-------------+------+----+-----------+------------+----------+----+--------------+---------------+--------+----------+\n",
      "|       1|   24686|  1034|          131|    44|   1|       1|           1|            1|    25|  52|1:28:01.283|     5281283|        45|   3|      1:29.238|        237.652|       1|  Hamilton|\n",
      "|     830|   24687|  1034|            9|    33|   3|       2|           2|            2|    19|  52|     +5.856|     5287139|        52|   1|      1:27.097|        243.494|       1|Verstappen|\n",
      "|     844|   24688|  1034|            6|    16|   4|       3|           3|            3|    15|  52|    +18.474|     5299757|        49|   9|      1:29.813|        236.130|       1|   Leclerc|\n",
      "|     817|   24689|  1034|            4|     3|   8|       4|           4|            4|    12|  52|    +19.650|     5300933|        49|   5|      1:29.482|        237.004|       1| Ricciardo|\n",
      "|     846|   24690|  1034|            1|     4|   5|       5|           5|            5|    10|  52|    +22.277|     5303560|        41|  12|      1:30.058|        235.488|       1|    Norris|\n",
      "|     839|   24691|  1034|            4|    31|   9|       6|           6|            6|     8|  52|    +26.937|     5308220|        50|   6|      1:29.491|        236.980|       1|      Ocon|\n",
      "|     842|   24692|  1034|          213|    10|  11|       7|           7|            7|     6|  52|    +31.188|     5312471|        52|   7|      1:29.603|        236.684|       1|     Gasly|\n",
      "|     848|   24693|  1034|            9|    23|  12|       8|           8|            8|     4|  52|    +32.670|     5313953|        52|   2|      1:28.689|        239.123|       1|     Albon|\n",
      "|     840|   24694|  1034|          211|    18|   6|       9|           9|            9|     2|  52|    +37.311|     5318594|        44|  13|      1:30.475|        234.402|       1|    Stroll|\n",
      "|      20|   24695|  1034|            6|     5|  10|      10|          10|           10|     1|  52|    +41.857|     5323140|        44|  15|      1:30.537|        234.242|       1|    Vettel|\n",
      "|     822|   24696|  1034|          131|    77|   2|      11|          11|           11|     0|  52|    +42.167|     5323450|        41|   4|      1:29.265|        237.580|       1|    Bottas|\n",
      "|     847|   24697|  1034|            3|    63|  20|      12|          12|           12|     0|  52|    +52.004|     5333287|        41|  16|      1:30.862|        233.404|       1|   Russell|\n",
      "|     832|   24698|  1034|            1|    55|   7|      13|          13|           13|     0|  52|    +53.370|     5334653|        47|  10|      1:29.948|        235.776|       1|     Sainz|\n",
      "|     841|   24699|  1034|           51|    99|  15|      14|          14|           14|     0|  52|    +54.205|     5335488|        49|  17|      1:30.977|        233.109|       1|Giovinazzi|\n",
      "|     849|   24700|  1034|            3|     6|  18|      15|          15|           15|     0|  52|    +54.549|     5335832|        44|  14|      1:30.501|        234.335|       1|    Latifi|\n",
      "|     154|   24701|  1034|          210|     8|  17|      16|          16|           16|     0|  52|    +55.050|     5336333|        49|   8|      1:29.782|        236.212|       1|  Grosjean|\n",
      "|       8|   24702|  1034|           51|     7|  16|      17|          17|           17|     0|  51|         \\N|          \\N|        49|  11|      1:29.973|        235.710|      11| Räikkönen|\n",
      "+--------+--------+------+-------------+------+----+--------+------------+-------------+------+----+-----------+------------+----------+----+--------------+---------------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hungarianResults.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf3f5957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hungarianResultsFinal: org.apache.spark.sql.DataFrame = [driverId: string, resultId: string ... 17 more fields]\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val hungarianResultsFinal = hungarianResults\n",
    "                            .withColumn(\"grid\", col(\"grid\").cast(\"integer\"))\n",
    "                            .withColumn(\"fastestLapSpeed\", col(\"fastestLapSpeed\").cast(\"integer\"))\n",
    "                            .withColumn(\"position\", col(\"position\").cast(\"integer\"))\n",
    "                            .withColumn(\"positionOrder\", col(\"positionOrder\").cast(\"integer\"))\n",
    "                            .withColumn(\"points\", col(\"points\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7b080b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainDf: org.apache.spark.sql.DataFrame = [driverId: string, resultId: string ... 17 more fields]\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Hungary Grand Prix for 2010 as training\n",
    "val trainDf = results\n",
    "  .filter($\"raceId\" === 348 && $\"position\" =!= \"\\\\N\")\n",
    "  .join(drivers.select($\"driverId\", $\"surname\"), Seq(\"driverId\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b201ed90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.classification.LogisticRegression\n",
       "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorAssembler}\n",
       "import org.apache.spark.ml.linalg.Vectors\n",
       "featureCols: Array[String] = Array(grid, fastestLapSpeed, positionOrder, points)\n",
       "assembler: org.apache.spark.ml.feature.VectorAssembler = VectorAssembler: uid=vecAssembler_3de043a7186f, handleInvalid=error, numInputCols=4\n",
       "dataWithFeatures: org.apache.spark.sql.DataFrame = [driverId: string, resultId: string ... 18 more fields]\n",
       "trainDf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [driverId: string, resultId: string ... 18 more fields]\n",
       "testDf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [driverId: string, resultId: string ... 18 more fields]\n",
       "lr: org.apache.spark.ml.classification....\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorAssembler}\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "\n",
    "// Filter results dataframe to include only valid positions\n",
    "// val hungarianResultsFiltered = hungarianResultsFinal.filter($\"position\" =!= \"\\\\N\")\n",
    "\n",
    "// Define the input features for the model\n",
    "val featureCols = Array(\"grid\", \"fastestLapSpeed\", \"positionOrder\", \"points\")\n",
    "\n",
    "// Create a VectorAssembler to combine the input features into a single vector\n",
    "val assembler = new VectorAssembler()\n",
    "  .setInputCols(featureCols)\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "// Apply the VectorAssembler to the data\n",
    "val dataWithFeatures = assembler.transform(hungarianResultsFinal)\n",
    "\n",
    "val trainDf = dataWithFeatures.sample(0.7)\n",
    "val testDf = dataWithFeatures.except(trainDf)\n",
    "\n",
    "\n",
    "// Define the LogisticRegression estimator\n",
    "val lr = new LogisticRegression()\n",
    "  .setLabelCol(\"position\")\n",
    "  .setFeaturesCol(\"features\")\n",
    "\n",
    "// Fit the estimator on the training set\n",
    "val model = lr.fit(trainDf)\n",
    "\n",
    "// Use the trained model to make predictions on the test set\n",
    "val predictions = model.transform(dataWithFeatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a9d5705f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "driverPredictions: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [surname: string, position: int ... 1 more field]\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val driverPredictions = predictions\n",
    "  .groupBy(\"surname\",\"position\")\n",
    "  .agg(avg(\"prediction\").as(\"prediction_driver\"))\n",
    "  .orderBy(asc(\"prediction_driver\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0eb2357a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----------------+\n",
      "|   surname|position|prediction_driver|\n",
      "+----------+--------+-----------------+\n",
      "|  Hamilton|       1|              1.0|\n",
      "|Verstappen|       2|              2.0|\n",
      "|   Leclerc|       3|              3.0|\n",
      "| Ricciardo|       4|              4.0|\n",
      "|    Norris|       5|              5.0|\n",
      "|     Gasly|       7|              7.0|\n",
      "|      Ocon|       6|              7.0|\n",
      "|     Albon|       8|              8.0|\n",
      "|    Stroll|       9|              9.0|\n",
      "|Giovinazzi|      14|             10.0|\n",
      "|    Vettel|      10|             10.0|\n",
      "|     Sainz|      13|             13.0|\n",
      "|    Bottas|      11|             13.0|\n",
      "|    Latifi|      15|             15.0|\n",
      "|   Russell|      12|             15.0|\n",
      "| Räikkönen|      17|             16.0|\n",
      "|  Grosjean|      16|             16.0|\n",
      "+----------+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "driverPredictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "263c6881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "britishResults: org.apache.spark.sql.DataFrame = [driverId: string, resultId: string ... 17 more fields]\n"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val britishResults = results\n",
    "  .filter($\"raceId\" === 1061 && $\"position\" =!= \"\\\\N\")\n",
    "  .join(drivers.select($\"driverId\", $\"surname\"), Seq(\"driverId\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1efc55e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "britishResultsFinal: org.apache.spark.sql.DataFrame = [driverId: string, resultId: string ... 17 more fields]\n"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val britishResultsFinal = britishResults\n",
    "                            .withColumn(\"grid\", col(\"grid\").cast(\"integer\"))\n",
    "                            .withColumn(\"fastestLapSpeed\", col(\"fastestLapSpeed\").cast(\"integer\"))\n",
    "                            .withColumn(\"position\", col(\"position\").cast(\"integer\"))\n",
    "                            .withColumn(\"positionOrder\", col(\"positionOrder\").cast(\"integer\"))\n",
    "                            .withColumn(\"points\", col(\"points\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e189c181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "britishtrainDf: org.apache.spark.sql.DataFrame = [driverId: string, resultId: string ... 17 more fields]\n"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val britishtrainDf = results\n",
    "  .filter($\"raceId\" === 908 && $\"position\" =!= \"\\\\N\")\n",
    "  .join(drivers.select($\"driverId\", $\"surname\"), Seq(\"driverId\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1150a33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.classification.LogisticRegression\n",
       "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorAssembler}\n",
       "import org.apache.spark.ml.linalg.Vectors\n",
       "featureCols: Array[String] = Array(grid, fastestLapSpeed, positionOrder, points)\n",
       "assembler: org.apache.spark.ml.feature.VectorAssembler = VectorAssembler: uid=vecAssembler_56b9da174fa6, handleInvalid=error, numInputCols=4\n",
       "dataWithFeatures: org.apache.spark.sql.DataFrame = [driverId: string, resultId: string ... 18 more fields]\n",
       "britishtrainDf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [driverId: string, resultId: string ... 18 more fields]\n",
       "testDf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [driverId: string, resultId: string ... 18 more fields]\n",
       "lr: org.apache.spark.ml.classifi...\n"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorAssembler}\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "\n",
    "// Filter results dataframe to include only valid positions\n",
    "// val hungarianResultsFiltered = hungarianResultsFinal.filter($\"position\" =!= \"\\\\N\")\n",
    "\n",
    "// Define the input features for the model\n",
    "val featureCols = Array(\"grid\", \"fastestLapSpeed\", \"positionOrder\", \"points\")\n",
    "\n",
    "// Create a VectorAssembler to combine the input features into a single vector\n",
    "val assembler = new VectorAssembler()\n",
    "  .setInputCols(featureCols)\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "// Apply the VectorAssembler to the data\n",
    "val dataWithFeatures = assembler.transform(britishResultsFinal)\n",
    "\n",
    "val britishtrainDf = dataWithFeatures.sample(0.9)\n",
    "val testDf = dataWithFeatures.except(britishtrainDf)\n",
    "\n",
    "\n",
    "// Define the LogisticRegression estimator\n",
    "val lr = new LogisticRegression()\n",
    "  .setLabelCol(\"position\")\n",
    "  .setFeaturesCol(\"features\")\n",
    "\n",
    "// Fit the estimator on the training set\n",
    "val model = lr.fit(britishtrainDf)\n",
    "\n",
    "// Use the trained model to make predictions on the test set\n",
    "val britishpredictions = model.transform(dataWithFeatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "631e706c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BritishdriverPredictions: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [surname: string, position: int ... 1 more field]\n"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val BritishdriverPredictions = britishpredictions\n",
    "  .groupBy(\"surname\",\"position\")\n",
    "  .agg(avg(\"prediction\").as(\"prediction_driver\"))\n",
    "  .orderBy(asc(\"prediction_driver\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "412a2196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----------------+\n",
      "|   surname|position|prediction_driver|\n",
      "+----------+--------+-----------------+\n",
      "|  Hamilton|       1|              1.0|\n",
      "|   Leclerc|       2|              2.0|\n",
      "|    Bottas|       3|              3.0|\n",
      "| Ricciardo|       5|              5.0|\n",
      "|    Norris|       4|              5.0|\n",
      "|     Sainz|       6|              6.0|\n",
      "|    Alonso|       7|              7.0|\n",
      "|    Stroll|       8|              8.0|\n",
      "|      Ocon|       9|              9.0|\n",
      "|   Tsunoda|      10|             10.0|\n",
      "|     Gasly|      11|             11.0|\n",
      "|Giovinazzi|      13|             13.0|\n",
      "|    Latifi|      14|             14.0|\n",
      "| Räikkönen|      15|             15.0|\n",
      "|   Russell|      12|             15.0|\n",
      "|     Pérez|      16|             16.0|\n",
      "|   Mazepin|      17|             17.0|\n",
      "|Schumacher|      18|             18.0|\n",
      "+----------+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BritishdriverPredictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9831901",
   "metadata": {},
   "source": [
    "### Team Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5c72ae3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hungarianTeamResults: org.apache.spark.sql.DataFrame = [constructorId: string, resultId: string ... 17 more fields]\n"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/// Hungary Grand Prix for 2020\n",
    "val hungarianTeamResults = results\n",
    "  .filter($\"raceId\" === 1034 && $\"position\" =!= \"\\\\N\")\n",
    "  .join(constructors.select($\"constructorId\", $\"name\"), Seq(\"constructorId\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "090d327f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hungarianTeamResultsFinal: org.apache.spark.sql.DataFrame = [constructorId: string, resultId: string ... 17 more fields]\n"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val hungarianTeamResultsFinal = hungarianTeamResults\n",
    "                            .withColumn(\"grid\", col(\"grid\").cast(\"integer\"))\n",
    "                            .withColumn(\"fastestLapSpeed\", col(\"fastestLapSpeed\").cast(\"integer\"))\n",
    "                            .withColumn(\"position\", col(\"position\").cast(\"integer\"))\n",
    "                            .withColumn(\"positionOrder\", col(\"positionOrder\").cast(\"integer\"))\n",
    "                            .withColumn(\"points\", col(\"points\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "91509660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainDfhungarianTeamResults: org.apache.spark.sql.DataFrame = [constructorId: string, resultId: string ... 17 more fields]\n"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/// Hungary Grand Prix for 2020\n",
    "val trainDfhungarianTeamResults = results\n",
    "  .filter($\"raceId\" === 348 && $\"position\" =!= \"\\\\N\")\n",
    "  .join(constructors.select($\"constructorId\", $\"name\"), Seq(\"constructorId\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ef046878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.classification.LogisticRegression\n",
       "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorAssembler}\n",
       "import org.apache.spark.ml.linalg.Vectors\n",
       "featureCols: Array[String] = Array(grid, fastestLapSpeed, positionOrder, points)\n",
       "assembler: org.apache.spark.ml.feature.VectorAssembler = VectorAssembler: uid=vecAssembler_172f4d0cc98c, handleInvalid=error, numInputCols=4\n",
       "dataWithFeatures: org.apache.spark.sql.DataFrame = [constructorId: string, resultId: string ... 18 more fields]\n",
       "trainDfhungarianTeamResults: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [constructorId: string, resultId: string ... 18 more fields]\n",
       "testDf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [constructorId: string, resultId: string ... 18 more fields]\n",
       "lr: ...\n"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorAssembler}\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "\n",
    "// Filter results dataframe to include only valid positions\n",
    "// val hungarianResultsFiltered = hungarianResultsFinal.filter($\"position\" =!= \"\\\\N\")\n",
    "\n",
    "// Define the input features for the model\n",
    "val featureCols = Array(\"grid\", \"fastestLapSpeed\", \"positionOrder\", \"points\")\n",
    "\n",
    "// Create a VectorAssembler to combine the input features into a single vector\n",
    "val assembler = new VectorAssembler()\n",
    "  .setInputCols(featureCols)\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "// Apply the VectorAssembler to the data\n",
    "val dataWithFeatures = assembler.transform(hungarianTeamResultsFinal)\n",
    "\n",
    "val trainDfhungarianTeamResults = dataWithFeatures.sample(0.7)\n",
    "val testDf = dataWithFeatures.except(trainDfhungarianTeamResults)\n",
    "\n",
    "\n",
    "// Define the LogisticRegression estimator\n",
    "val lr = new LogisticRegression()\n",
    "  .setLabelCol(\"position\")\n",
    "  .setFeaturesCol(\"features\")\n",
    "\n",
    "// Fit the estimator on the training set\n",
    "val model = lr.fit(trainDfhungarianTeamResults)\n",
    "\n",
    "// Use the trained model to make predictions on the test set\n",
    "val HungarianTeampredictions = model.transform(dataWithFeatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fef5baf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HungarianTeampredictionsFinal: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [name: string, prediction_team: double]\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val HungarianTeampredictionsFinal = HungarianTeampredictions\n",
    "  .groupBy(\"name\")\n",
    "  .agg(min(\"prediction\").as(\"prediction_team\"))\n",
    "  .orderBy(asc(\"prediction_team\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "55460f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+\n",
      "|          name|prediction_team|\n",
      "+--------------+---------------+\n",
      "|      Mercedes|            2.0|\n",
      "|       Ferrari|            2.0|\n",
      "|       McLaren|            4.0|\n",
      "|Alpine F1 Team|            7.0|\n",
      "|  Aston Martin|            8.0|\n",
      "|    AlphaTauri|           10.0|\n",
      "|      Williams|           12.0|\n",
      "|    Alfa Romeo|           13.0|\n",
      "|      Red Bull|           16.0|\n",
      "|  Haas F1 Team|           17.0|\n",
      "+--------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HungarianTeampredictionsFinal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d893ecd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "britishTeamResults: org.apache.spark.sql.DataFrame = [constructorId: string, resultId: string ... 17 more fields]\n"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val britishTeamResults = results\n",
    "  .filter($\"raceId\" === 1061 && $\"position\" =!= \"\\\\N\")\n",
    "  .join(constructors.select($\"constructorId\", $\"name\"), Seq(\"constructorId\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "18d94356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "britishTeamResultsFinal: org.apache.spark.sql.DataFrame = [constructorId: string, resultId: string ... 17 more fields]\n"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val britishTeamResultsFinal = britishTeamResults\n",
    "                            .withColumn(\"grid\", col(\"grid\").cast(\"integer\"))\n",
    "                            .withColumn(\"fastestLapSpeed\", col(\"fastestLapSpeed\").cast(\"integer\"))\n",
    "                            .withColumn(\"position\", col(\"position\").cast(\"integer\"))\n",
    "                            .withColumn(\"positionOrder\", col(\"positionOrder\").cast(\"integer\"))\n",
    "                            .withColumn(\"points\", col(\"points\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b5d09882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainDfbritishTeamResults: org.apache.spark.sql.DataFrame = [constructorId: string, resultId: string ... 17 more fields]\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/// Hungary Grand Prix for 2020\n",
    "val trainDfbritishTeamResults = results\n",
    "  .filter($\"raceId\" === 908 && $\"position\" =!= \"\\\\N\")\n",
    "  .join(constructors.select($\"constructorId\", $\"name\"), Seq(\"constructorId\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "003223eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.classification.LogisticRegression\n",
       "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorAssembler}\n",
       "import org.apache.spark.ml.linalg.Vectors\n",
       "featureCols: Array[String] = Array(grid, fastestLapSpeed, positionOrder, points)\n",
       "assembler: org.apache.spark.ml.feature.VectorAssembler = VectorAssembler: uid=vecAssembler_45b393a2a63b, handleInvalid=error, numInputCols=4\n",
       "dataWithFeatures: org.apache.spark.sql.DataFrame = [constructorId: string, resultId: string ... 18 more fields]\n",
       "trainDfbritishTeamResults: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [constructorId: string, resultId: string ... 18 more fields]\n",
       "testDf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [constructorId: string, resultId: string ... 18 more fields]\n",
       "lr: or...\n"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorAssembler}\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "\n",
    "// Filter results dataframe to include only valid positions\n",
    "// val hungarianResultsFiltered = hungarianResultsFinal.filter($\"position\" =!= \"\\\\N\")\n",
    "\n",
    "// Define the input features for the model\n",
    "val featureCols = Array(\"grid\", \"fastestLapSpeed\", \"positionOrder\", \"points\")\n",
    "\n",
    "// Create a VectorAssembler to combine the input features into a single vector\n",
    "val assembler = new VectorAssembler()\n",
    "  .setInputCols(featureCols)\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "// Apply the VectorAssembler to the data\n",
    "val dataWithFeatures = assembler.transform(britishTeamResultsFinal)\n",
    "\n",
    "val trainDfbritishTeamResults = dataWithFeatures.sample(0.7)\n",
    "val testDf = dataWithFeatures.except(trainDfbritishTeamResults)\n",
    "\n",
    "\n",
    "// Define the LogisticRegression estimator\n",
    "val lr = new LogisticRegression()\n",
    "  .setLabelCol(\"position\")\n",
    "  .setFeaturesCol(\"features\")\n",
    "\n",
    "// Fit the estimator on the training set\n",
    "val model = lr.fit(trainDfbritishTeamResults)\n",
    "\n",
    "// Use the trained model to make predictions on the test set\n",
    "val BritishTeampredictions = model.transform(dataWithFeatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "aab9156e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BritishTeampredictionsFinal: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [name: string, prediction_team: double]\n"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val BritishTeampredictionsFinal = BritishTeampredictions\n",
    "  .groupBy(\"name\")\n",
    "  .agg(min(\"prediction\").as(\"prediction_team\"))\n",
    "  .orderBy(asc(\"prediction_team\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b0310aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+\n",
      "|          name|prediction_team|\n",
      "+--------------+---------------+\n",
      "|      Mercedes|            1.0|\n",
      "|       Ferrari|            3.0|\n",
      "|       McLaren|            4.0|\n",
      "|Alpine F1 Team|            7.0|\n",
      "|  Aston Martin|            8.0|\n",
      "|    AlphaTauri|           10.0|\n",
      "|      Red Bull|           11.0|\n",
      "|      Williams|           12.0|\n",
      "|    Alfa Romeo|           13.0|\n",
      "|  Haas F1 Team|           17.0|\n",
      "+--------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BritishTeampredictionsFinal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2fd4f6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fileName: String = britishTeam.csv\n"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fileName = \"britishTeam.csv\"\n",
    "\n",
    "BritishTeampredictionsFinal.coalesce(1)\n",
    "  .write\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"delimiter\", \",\")\n",
    "  .csv(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1628027f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
